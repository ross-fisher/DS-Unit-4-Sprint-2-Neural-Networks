{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# https://youtu.be/5ECD8J3dvDQ\n",
    "#a = tf.contant(5)\n",
    "#b = tf.constant(5)\n",
    "#c = a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image classification with subtext in one full model\n",
    "# Question Input, Image Input\n",
    "# Embedding     \n",
    "#  LSTM           Conv2D/MaxPooling2D stack\n",
    "#         concatenate\n",
    "#         Dense / softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Conv2D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8b6efa4443c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Image classifier encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvision_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m vision_model.add(Conv2D(64, (3, 3),\n\u001b[0m\u001b[1;32m      6\u001b[0m                  \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                  input_shape=(224,224,3)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Conv2D' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# example for image encoding\n",
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(224,224,3)))\n",
    "vision_model.add(MaxPooling2D())\n",
    "vision_modell.add(Flatten())\n",
    "\n",
    "# Input layer for the functional api\n",
    "image_input = Input(shape=(224,224,3))\n",
    "encoded_image = vision_model(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-269e034268e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# examplef or text incoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m question_input = Input(shape=(100,),\n\u001b[0m\u001b[1;32m      3\u001b[0m                        \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                        name='Question')\n\u001b[1;32m      5\u001b[0m embedded = Embedding(input_dim=10000,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "# examplef or text incoding\n",
    "question_input = Input(shape=(100,),\n",
    "                       dtype='int32',\n",
    "                       name='Question')\n",
    "embedded = Embedding(input_dim=10000,\n",
    "                     output_dim=256,\n",
    "                     input_length=100)(question_input)\n",
    "\n",
    "encoded_question = LSTM(256)(embedded_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-96b090326c7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m merged = layers.concatenate([encoded_image,\n\u001b[0m\u001b[1;32m      2\u001b[0m                              encoded_question])\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train a classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "# concatenate the layers \n",
    "merged = layers.concatenate([encoded_image,\n",
    "                             encoded_question])\n",
    "\n",
    "# train a classifier\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.dense_1 = layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    # forward\n",
    "    def call(self, inputs):\n",
    "        x=  self.dense_1(inputs)\n",
    "        # example replacing the activation function within the call\n",
    "        x = tf.nn.relu(x) \n",
    "        return self.dense_2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vqa_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cdba9c80372e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvqa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vqa_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(vqa_model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data,\n",
    "         epchos=10,\n",
    "         validation_data=val_data,\n",
    "         callbacks=[EarlyStopping(),\n",
    "                    TensorBoard(),\n",
    "                    ModelCheckpoint()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function adds performance\n",
    "@tf.function\n",
    "def train_step(features, labels)\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(features, training=True)\n",
    "        loss = loss_fn(labels, logits)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and Numpy\n",
    "Tensorflow has functions that mimic numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5 2]\n",
      " [1 3]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[5, 2], [1, 3]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2],\n",
       "       [1, 3]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-0.03265592, -0.06797294],\n",
       "       [ 0.3151153 , -1.5585144 ]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(2, 2), mean=0., stddev=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45324567, -0.13361892],\n",
       "       [-1.9691302 , -0.18071455]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(2, 2), mean=0., stddev=1.).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=16, shape=(), dtype=int32, numpy=25>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant(5)\n",
    "tf.square(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    y = x * x\n",
    "    \n",
    "dy_dx = g.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22, shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy_dx # 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example to find values of m and b for a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scatterplot(m=0.1, b=0.2, n=100):\n",
    "    x = tf.random.uniform(shape=(n,))\n",
    "    # move intercept around\n",
    "    noise = tf.random.normal(shape=(len(x),), stddev=0.02)\n",
    "    y = m * x + b + noise\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = make_scatterplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff4444e0e48>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAcKUlEQVR4nO3df6wdZ33n8fcnThx2m1JYx7tqbd/YLUbCENSwB6duBQ7BSQ1V7a1aFcNGSWgWtwGvls3uah2lSbO2ULaJili0VonpWtsgsYagpboVDt6QtQWtrltfN9mkdpTm4oLjgBpjflSRhRPH3/1j5uLx8f0x556ZM78+L8m6Z36d8zzH937nme/zzDOKCMzMrL0uq7oAZmZWLgd6M7OWc6A3M2s5B3ozs5ZzoDcza7nLqy5Av6uvvjpWrlxZdTHMzBrlyJEj34uIpTNtq12gX7lyJZOTk1UXw8ysUSR9e7ZtTt2YmbWcA72ZWcs50JuZtVyuQC9po6TnJE1J2j7D9t+T9IykpyT9haQ16fqbJB1Jtx2RdGPRFTAzs7nNG+glLQJ2Ae8D1gAfnA7kGZ+PiGsj4heBB4FPpuu/B/x6RFwL3AZ8rrCSm5lZLnla9GuBqYg4HhGvAHuBzdkdIuIfM4s/BUS6/smI+E66/ijwTyRdOXyxzcwsrzzDK5cBL2SWTwLX9+8k6WPAXcBiYKYUzW8CfxMRZ2c4diuwFWBsbCxHkczMmmliAg4ehBtugHXrRvOZhY2jj4hdwC5JHwJ+nyRVA4CktwJ/CNw8y7G7gd0AvV7P8yabWStNTMB73wuvvAKLF8MTT4wm2OdJ3bwIrMgsL0/XzWYv8K+mFyQtB74M3BoR31xIIc3M2uDgwSTIv/Za8vPgwdF8bp5AfxhYLWmVpMXAFmA8u4Ok1ZnFXwOeT9e/AfgKsD0i/rKYIpuZNdMNNyQt+UWLkp833DCaz503dRMR5yRtA/YDi4A9EXFU0g5gMiLGgW2SNgCvAj/gQtpmG/Am4D5J96Xrbo6Il4quiJlZ3a1bl6RrRp2jV90eJdjr9cJz3ZiZDUbSkYjozbTNd8aambWcA72ZWcs50JtZ60xMwAMPJD+thvPRm5kNo6qx6nXmFr2ZtUpVY9XrzIHezFqlqrHqdebUjZm1SlVj1evMgd7MWmfduuoD/KCTl5U52ZkDvZlZwQbtEC67A9k5ejOzgg3aIVx2B7IDvZlZwQbtEC67A9mpGzOzgg3aIVx2B7InNTMzo5onPxVprknN3KI3s84bxd20VZ5IHOjNrPNm6gwtMhhXPS2DO2PNrPPK7gyteloGt+itdpqeK7XmKbszdPpEMt2iH/W0DA70VitVX+La6NXlxF7m3bRVT8vgQG+1Unau1OqlSyf2KqdlyJWjl7RR0nOSpiRtn2H770l6RtJTkv5C0prMtrvT456T9KtFFt7axzMPdkvVueuumLdFL2kRsAu4CTgJHJY0HhHHMrt9PiI+k+6/CfgksDEN+FuAtwI/B3xN0psj4rWC62EtUfUlro1W1bnrrsiTulkLTEXEcQBJe4HNwE8CfUT8Y2b/nwKm78LaDOyNiLPA30uaSt/PD/iyWdVh5kEbDZ/YRyNPoF8GvJBZPglc37+TpI8BdwGLgRszxx7qO3bZDMduBbYCjI2N5Sm3mbWET+zlK2wcfUTsiohfAP4z8PsDHrs7InoR0Vu6dGlRRTJrND/g2oqSp0X/IrAis7w8XTebvcAfL/BYM6Nbo1GsfHla9IeB1ZJWSVpM0rk6nt1B0urM4q8Bz6evx4Etkq6UtApYDfz18MW2LupSC9ejUaxI87boI+KcpG3AfmARsCcijkraAUxGxDiwTdIG4FXgB8Bt6bFHJX2RpOP2HPAxj7ixhehaC7ero1HqcvNU2+S6YSoi9gH7+tbdl3n97+Y49hPAJxZaQDPo3o1UXRyN0rWT+Sj5zlhrhC62cLs2GqVrJ/NRcqC3RuhiC7drFnIyd6onHwd6a4yutXC7ZtCTuVM9+TnQm1mhhmllD3Iyd6onPwd6MyvMKFvZXey3WSg/YcrMCjPK8f/TqZ6dO5uZthnlfSFu0Zs1XJ06JJvWyq7quxt1/4IDvVmD1a1DcpSjoyYmks949VW44orBc/RVfnej7l9w6sasweo4VcK6dXD33eUHzUceSeockfx85JHBjq/yuxv1A3bcojdrsKalSuqkyu9u1PeFKCLm32uEer1eTE5OVl0Ms8aoU45+lCYm4D3vuRCoDxwYvP5t+u4kHYmI3ozbHOjNLK+6Bca6ladKcwV6p27MLJdhOi/LCsi+WzofB3ozy2WhI0XqNjJoWE28inCgN7NcFtp5WeRQwqqDbFNPWg70ZpbLQkeKFDW6pQ5Btqnz6zjQm1luC8mJFzWUsA5Btv+ktWRJMo1B3dM4DvRmVroiOk3rcM9A9qS1ZAl8/OPNSOPkujNW0kZJz0makrR9hu13STom6WlJT0i6JrPtQUlHJT0r6dOSVGQFzKwb6jKJ2fSdv6dPX7jCOHsW7r+/vg+unzfQS1oE7ALeB6wBPihpTd9uTwK9iHg78CXgwfTYXwZ+BXg78DbgncD6wkpvZp0yqukV8pi+wrjsMjh/Hr72taQPoY7BPk+Lfi0wFRHHI+IVYC+wObtDRByIiDPp4iFg+fQm4HXAYuBK4ArgH4oouJlZlaavMDZsuBDs6zLfUL88gX4Z8EJm+WS6bjZ3AI8BRMQEcAD4bvpvf0Q823+ApK2SJiVNnjp1Km/ZzSyHUc573jXr1iUpmyuvHN0EZQtRaGespFuAHml6RtKbgLdwoYX/uKR3RcQ3ssdFxG5gNyRTIBRZJrMmKmq8eB2GJLZdEx5cnyfQvwisyCwvT9ddRNIG4B5gfUScTVf/BnAoIl5O93kMWAd8o/94M0sUGZyHHZJY9Q1KTVH3qRjypG4OA6slrZK0GNgCjGd3kHQd8DCwKSJeymw6AayXdLmkK0ha+pekbszsgiLnSR9m3vPpE86991bbyejU0/DmbdFHxDlJ24D9wCJgT0QclbQDmIyIceAh4Crg0XT05ImI2EQyAudG4BmSjtmvRsSfl1MVs3Yocrz4MGmFOtyg5NRTMXLl6CNiH7Cvb919mdcbZjnuNeB3hymgWdcUnfNdaFqhDjco1eFk0wa+M9ashuqQ861DJ2MdTjZt4EBvrebOxOFUfcKpw8mmDRzorbXakt+dmLjw4Otbb21mHaxaDvTWWm3I704/F/VsOmB5z55m1mOhyj5Zd+WKz4HeWqup+d1s8Jk+WU179dVuBfoyT9ZtueLLw4HeWquJ+d3+4POpTyU/p1v0V1zRnBNWEco8Wbfhii8vB3prtao7EwfVH3xOn4YDB7qboy/zZN3UK76FcKA3q5GZgk/TTlZFK6v+TbziWygHerOaue225GedWu9t7bTsyknUgd5sgYoOfv35+VtvHf49i9ClTsu2yvUoQTO7WBkTfhU5mVmR6lquvDwpmgO92YICQTb4FfW80GFmmixTXcuVx3wn5K6cBJy6sU5baFpiOvidPXvheaHf+MZwaY28nYNFpIwGeY8md1rONYSySykpB3rrtIWOpZ4OfvffnwT57PNChwkW83UOFhGcFvIeTe20nGsIZZfG0Tt1Y502TFqiiueFFpEvb3rOfRDTJ+SdOy89oTU5JTUot+it04ZNS4w6rVHETT553qNNwylnuxppckpqUIqo17O4e71eTE5OVl0Ms9oqO0ffpdx1m0g6EhG9mba5RW/WMEXky+d6jy7lrrsiV45e0kZJz0makrR9hu13STom6WlJT0i6JrNtTNL/kfRsus/K4opvZkXrUu66K+Zt0UtaBOwCbgJOAocljUfEscxuTwK9iDgj6U7gQeAD6bZHgE9ExOOSrgLOF1oDMytUl3LXXZEndbMWmIqI4wCS9gKbgZ8E+og4kNn/EHBLuu8a4PKIeDzd7+WCym1mJcjm7u++u+rSWFHyBPplwAuZ5ZPA9XPsfwfwWPr6zcAPJf1vYBXwNWB7RLyWPUDSVmArwNjYWL6Sm1mh3AnbXoWOo5d0C9ADHkpXXQ68C/iPwDuBnwdu7z8uInZHRC8iekuXLi2ySGaWU5fG13dNnkD/IrAis7w8XXcRSRuAe4BNEZE+D4eTwFMRcTwizgF/BrxjuCKbVa+Nc6QM0wnbxu+jTfKkbg4DqyWtIgnwW4APZXeQdB3wMLAxIl7qO/YNkpZGxCngRsCD5K3R2priWGgnbFu/jzaZt0WftsS3AfuBZ4EvRsRRSTskbUp3ewi4CnhU0lOSxtNjXyNJ2zwh6RlAwGdLqIfZyLQ5xbFuXdIJO0igbvP30Ra5bpiKiH3Avr5192Veb5jj2MeBty+0gGZ106Vnjebh76P+fGes2YDqNs686nlp6vZ92KU8141ZSUYRgJ0ft2me68bmVHWLsI1GFYA9L43l4UDfcVW3CNt6khlVAHZ+3PJwoO+4KluEVZ9kyjSqAOz8uOXhQN9xVbYI25J2mOmqZJQBuKmP+bPRcaDvuCpbhFWeZIpKGc11VdKEANzW1JldzIHeKgtIVZ1k+oPzpz4Fp08vrAxNvippc+rMLuZAb5Wq4iSTDc5nz8K2bXD+/MKCXZM7Q5t8krLBFDp7pVkTZCfvuuyyJNAt9Pb96auSnTub1yKu05OkPClaudyit87JpoyWLIGPfzx/i3y2jtcmBfhpdRmx4xRS+RzorRGK7jTMBudrr8333m0MSHU4STmFVD4H+gbq2kiJsgNs3mBX94DU1N+LJvdzNIUDfcO0sVU5n7oE2DoHpCb/XtQlhdRmDvQNM1/Qa2qrbi5lBdhBv6s6B6S6nAwXqg4ppDZzoG+YuYJek1t1cykjwC70u6prQKrz1YZVz4G+YeYKek1v1c2l6AA713fVxKuiOl9tWPUc6BtotqDnVl0+ExNw4kQyfhwu/q6afFVU16sNq16uG6YkbZT0nKQpSdtn2H6XpGOSnpb0hKRr+ra/XtJJSf+9qILbpZp8886oTAfyz34WJPjIRy7+rvz8U2ujeVv0khYBu4CbgJPAYUnjEXEss9uTQC8izki6E3gQ+EBm+07g68UV22ZTdquuiWmNrGwgBxgbu7geviqyNsqTulkLTEXEcQBJe4HNwE8CfUQcyOx/CLhlekHSvwT+BfBVYMbHXHVV04Jmk9Ma0+YL5M51WxvlCfTLgBcyyyeB6+fY/w7gMQBJlwF/RBL4N8x2gKStwFaAsbGxHEVqjtmCeRODZhs6e/ME8ibkupvWSLBqFdoZK+kWklb7+nTVR4F9EXFS0qzHRcRuYDckDwcvskx5lfGHM1cwP3gwmTnx/PnkZxOC5kLTGnULSk0I5HOpqpFQt/9Hyy9PoH8RWJFZXp6uu4ikDcA9wPqIOJuuXge8S9JHgauAxZJejohLOnSrVNYfziOPwI9/DBGXtoCXLEmCPCQ/lywZ/vPKNkhaYzoo9E8a1oQrl7qr4sqqiVegdkGeQH8YWC1pFUmA3wJ8KLuDpOuAh4GNEfHS9PqI+NeZfW4n6bCtVZCHcv5wJiZgz54kyANcfvnFLeDTp5Mpcs+fT36ePj3c541KntZwNihISR3Pn29uuqduqugwbkParsvmDfQRcU7SNmA/sAjYExFHJe0AJiNiHHiIpMX+aJqiORERm0osd6HK+MM5ePDCyA4JPvzhS0d3XHllO0d3ZIPCZZcl49Wl9tWzKlV0GHs0UrMpopKU+Kx6vV5MTk6O/HOLzj/mudRta86zyEf1WX209fe1LSQdiYgZRzY60Jeoy38YXa67WRU6G+gdbMysK+YK9K2d68ajBJqjqhOyGwLWFa0N9B4l0AxVjgl3Q8C6ItekZk1Upyfc2+yqmkTMk5dZl7S2Re85S5qhqmF7Hi5oXdLqzlhrBufozYbX2VE3ZmZdMVegb22OvskmJuCBB5KfZmbDam2OvqmaPhrE6RCz+nGgr5kmDwtt+knKrK2cuqmZJg8L9ZBFs3pqVYu+bmmDhZSnycNCPWTRrJ5aE+hHkTYYJHAPU54qnoBUxEmyyScpszZrTaAvO7c9aOCeLY1RxyBY5Emy6Y/pM2uj1uToy85tD5p/7i/PkiVJML333uRnnYZOOrdu1m6tadGXnTYYNP/cX546j6Zxbt2s3VoT6GHutMGwOej5TiQzvX9/eeoaTJ1bN2u3XFMgSNoI/DeSZ8b+SUT8177tdwH/BjgHnAJ+JyK+LekXgT8GXg+8BnwiIr4w12eVMQVC2R21ed+/bqOC6szfldlghnrwiKRFwC7gJuAkcFjSeEQcy+z2JNCLiDOS7gQeBD4AnAFujYjnJf0ccETS/oj44ZB1GkjZaZO87++Oynx845VZsfJ0xq4FpiLieES8AuwFNmd3iIgDEXEmXTwELE/X/11EPJ++/g7wErC0qMLnVXZHbZNvcqojdw6bFStPjn4Z8EJm+SRw/Rz73wE81r9S0lpgMfDNGbZtBbYCjI2N5SjSYMrOQTvHPbdB0zDuHDYrVqGdsZJuAXrA+r71Pwt8DrgtIs73HxcRu4HdkOToiyzTtLLTJk7LzGwhaRifOM2KlSfQvwisyCwvT9ddRNIG4B5gfUSczax/PfAV4J6IODRcca1pFto/4hOnWXHy5OgPA6slrZK0GNgCjGd3kHQd8DCwKSJeyqxfDHwZeCQivlRcsa0p3H9hVr15W/QRcU7SNmA/yfDKPRFxVNIOYDIixoGHgKuARyUBnIiITcBvA+8Glki6PX3L2yPiqeKrYnXkNIxZ9fwoQTOzFvCjBM3MOsyB3sys5RzozcxazoG+oSYm4IEH6jXdsZnVU6tmr+wKzwVjZoNwi76BPBeMmQ3Cgb6BfBOSmQ3CqZsG8k1IZjYIB/qG8lwwZpaXUzdmZi3nQG+14mGjZsVz6sZqw8NGzcrhFr3VhoeNmpXDgd5qw8NGzcrh1E2HDfos17J52KhZORzoO6qu+XAPGzUrXqtSNx6xkZ/z4Wbd0ZoWfZUt1LqlQPKYzodPf1/Oh5u1V64WvaSNkp6TNCVp+wzb75J0TNLTkp6QdE1m222Snk//3VZk4bOqaqFOn2DuvTf52ZSriel8+M6d9UnbmFk55m3RS1oE7AJuAk4ChyWNR8SxzG5PAr2IOCPpTuBB4AOS/hnwB0APCOBIeuwPiq5IVS3UmU4wTQmazoebdUOeFv1aYCoijkfEK8BeYHN2h4g4EBFn0sVDwPL09a8Cj0fE99Pg/jiwsZiiX6yqFqqHBJpZ3eXJ0S8DXsgsnwSun2P/O4DH5jh22SAFHEQVLVQPCTSzuiu0M1bSLSRpmvUDHrcV2AowNjZWZJEWZNDOVadAzKzO8gT6F4EVmeXl6bqLSNoA3AOsj4izmWNv6Dv2YP+xEbEb2A3Q6/UiR5lKU9fx5WZmC5UnR38YWC1plaTFwBZgPLuDpOuAh4FNEfFSZtN+4GZJb5T0RuDmdF1tdXV8ue9BMGuveVv0EXFO0jaSAL0I2BMRRyXtACYjYhx4CLgKeFQSwImI2BQR35e0k+RkAbAjIr5fSk0K0sXx5b6KMWu3XDn6iNgH7Otbd1/m9YY5jt0D7FloAUeti52rTR4iambza82dsUXqWudqF69izLrEgd46eRVj1iUO9AZ07yrGrEtaNXul5edRNmbd4RZ9B3mUjVm3uEXfQV29V8CsqxzoZ9D2tIYnYjPrFqdu+nQhreFRNmbd4kDfpys3D3mUjVl3OHXTx2kNM2sbt+j7OK1hZm3jQD8DpzXMrE1anbpp++gZM7M8Wtui78LoGTOzPFrbovdNQWZmidYGeo+eMTNLtDZ149EzZmaJ1gZ68OgZMzNocerGzMwSuQK9pI2SnpM0JWn7DNvfLelvJJ2T9Ft92x6UdFTSs5I+rfTp4WZmNhrzBnpJi4BdwPuANcAHJa3p2+0EcDvw+b5jfxn4FeDtwNuAdwLrhy61mZnllidHvxaYiojjAJL2ApuBY9M7RMS30m3n+44N4HXAYkDAFcA/DF1qMzPLLU/qZhnwQmb5ZLpuXhExARwAvpv+2x8Rz/bvJ2mrpElJk6dOncrz1mZmllOpnbGS3gS8BVhOcnK4UdK7+veLiN0R0YuI3tKlS8sskplZ5+QJ9C8CKzLLy9N1efwGcCgiXo6Il4HHAA94NDMboTyB/jCwWtIqSYuBLcB4zvc/AayXdLmkK0g6Yi9J3RTJE5mZmV1s3s7YiDgnaRuwH1gE7ImIo5J2AJMRMS7pncCXgTcCvy7pv0TEW4EvATcCz5B0zH41Iv68rMp4IjMzs0vlujM2IvYB+/rW3Zd5fZgkpdN/3GvA7w5Zxty68hhAM7NBtOrOWE9kZmZ2qVbNddPWicwmJtpXJzMbnVYFemjfRGbudzCzYbUqddNGfoCKmQ3Lgb7m3O9gZsNqXeqmbdra72Bmo+NA3wBt63cws9Fy6sbMrOUc6M3MWs6B3sys5RzozcxazoHezKzlHOjNzFpOEVF1GS4i6RTw7QUcejXwvYKLU3ddrDN0s96uczcMU+drImLGR/TVLtAvlKTJiOhVXY5R6mKdoZv1dp27oaw6O3VjZtZyDvRmZi3XpkC/u+oCVKCLdYZu1tt17oZS6tyaHL2Zmc2sTS16MzObgQO9mVnLNS7QS9oo6TlJU5K2z7D9SklfSLf/laSVoy9lsXLU+S5JxyQ9LekJSddUUc4izVfnzH6/KSkkNX4YXp46S/rt9P/6qKTPj7qMZcjx+z0m6YCkJ9Pf8fdXUc6iSNoj6SVJfzvLdkn6dPp9PC3pHUN/aEQ05h+wCPgm8PPAYuD/AWv69vko8Jn09RbgC1WXewR1fg/wT9PXd3ahzul+Pw18HTgE9Kou9wj+n1cDTwJvTJf/edXlHlG9dwN3pq/XAN+qutxD1vndwDuAv51l+/uBxwABvwT81bCf2bQW/VpgKiKOR8QrwF5gc98+m4E/TV9/CXivJI2wjEWbt84RcSAizqSLh4DlIy5j0fL8PwPsBP4Q+PEoC1eSPHX+CLArIn4AEBEvjbiMZchT7wBen77+GeA7Iyxf4SLi68D359hlM/BIJA4Bb5D0s8N8ZtMC/TLghczyyXTdjPtExDngR8CSkZSuHHnqnHUHSWugyeatc3o5uyIivjLKgpUoz//zm4E3S/pLSYckbRxZ6cqTp973A7dIOgnsA/7taIpWmUH/5uflRwm2iKRbgB6wvuqylEnSZcAngdsrLsqoXU6SvrmB5Krt65KujYgfVlqq8n0Q+J8R8UeS1gGfk/S2iDhfdcGaomkt+heBFZnl5em6GfeRdDnJpd7pkZSuHHnqjKQNwD3Apog4O6KylWW+Ov808DbgoKRvkeQxxxveIZvn//kkMB4Rr0bE3wN/RxL4myxPve8AvggQERPA60gm/2qrXH/zg2haoD8MrJa0StJiks7W8b59xoHb0te/BfzfSHs4GmreOku6DniYJMi3IW87Z50j4kcRcXVErIyIlST9EpsiYrKa4hYiz+/2n5G05pF0NUkq5/goC1mCPPU+AbwXQNJbSAL9qZGWcrTGgVvT0Te/BPwoIr47zBs2KnUTEeckbQP2k/TW74mIo5J2AJMRMQ78D5JLuymSDo8t1ZV4eDnr/BBwFfBo2u98IiI2VVboIeWsc6vkrPN+4GZJx4DXgP8UEU2+Ws1b7/8AfFbSvyfpmL29yY03Sf+L5IR9ddrv8AfAFQAR8RmSfoj3A1PAGeDDQ39mg78vMzPLoWmpGzMzG5ADvZlZyznQm5m1nAO9mVnLOdCbmbWcA72ZWcs50JuZtdz/B8K+p0mxvFVbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.Variable(0.)\n",
    "b = tf.Variable(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    y = m * x + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def squared_error(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loss 0.06540269\n"
     ]
    }
   ],
   "source": [
    "loss = squared_error(predict(x_train), y_train)\n",
    "print(\"Starting Loss\", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss 0.06540268659591675\n",
      "Step 20, Loss 0.0006531482795253396\n",
      "Step 40, Loss 0.0003661966766230762\n",
      "Step 60, Loss 0.0003624212113209069\n",
      "Step 80, Loss 0.00036047465982846916\n",
      "Step 100, Loss 0.0003589870175346732\n",
      "Step 120, Loss 0.00035784687497653067\n",
      "Step 140, Loss 0.00035697323619388044\n",
      "Step 160, Loss 0.00035630364436656237\n",
      "Step 180, Loss 0.00035579048562794924\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "steps = 200\n",
    "# gradient descent manually, would normally use model.fit\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = predict(x_train)\n",
    "        loss = squared_error(predictions, y_train)\n",
    "        \n",
    "    gradients = tape.gradient(loss, [m, b])\n",
    "    m.assign_sub(gradients[0] * learning_rate)\n",
    "    b.assign_sub(gradients[1] * learning_rate)\n",
    "    if i % 20 == 0:\n",
    "        print(f'Step {i}, Loss {loss.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
